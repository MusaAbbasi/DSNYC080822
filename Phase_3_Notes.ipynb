{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a class\n",
    "class ExampleClass:\n",
    "    pass #at a minimum an empty class must contain pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    \n",
    "    def bark(self):\n",
    "        return 'I am actually going to bark this time. bark!'\n",
    "        \n",
    "    def who_am_i(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am actually going to bark this time. bark!\n",
      "<__main__.Dog object at 0x000002A2A7736280>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to use a class and the defined instance methods\n",
    "rex = Dog()\n",
    "print(rex.bark())\n",
    "print(rex.who_am_i())\n",
    "rex == rex.who_am_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes = Fields, properties of object insatance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of super and subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Musician(object):\n",
    "    \n",
    "    def __init__(self, name): # We'll set name at instantiation time to demonstrate passing in arguments to super().__init__()\n",
    "        self.name = name\n",
    "        self.band = \"The Beatles\"\n",
    "    \n",
    "    def tune_instrument(self):\n",
    "        print(\"Tuning Instrument!\")\n",
    "    \n",
    "    def practice(self):\n",
    "        print(\"Practicing!\")\n",
    "        \n",
    "    def perform(self):\n",
    "        print(\"Hello New York!\")\n",
    "        \n",
    "class Singer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)  # Notice how we pass in name argument from init to the super().__init() method, because it expects it\n",
    "        self.role = \"Singer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print(\"No tuning needed -- I'm a singer!\")\n",
    "    \n",
    "class Guitarist(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"Strumming the old 6 string!\")\n",
    "        \n",
    "class Bass_Guitarist(Guitarist):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Bass Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"I play the Seinfeld Theme Song when I get bored\")\n",
    "        \n",
    "    def perform(self):\n",
    "        super().perform()\n",
    "        print(\"Thanks for coming out!\")\n",
    "        \n",
    "class Drummer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Drummer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print('Where did I put those drum sticks?')\n",
    "        \n",
    "    def practice(self):\n",
    "        print('Why does my chair still say \"Pete Best\"?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative: $$ \\frac{df(x)}{dx} $$\n",
    "\n",
    "The instaneous slope of $f(x)$ at $x = c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define as limit of slope of chord between f(x + h) and f(x): $$\\frac{\\Delta y}{\\Delta x} $$ \n",
    "- As $\\Delta x \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding $w_1$ minimizing cost function:\n",
    "\n",
    "$$L = \\sum_{i=1}^N (y_i - x_i w_1)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "w = weight\n",
    "\n",
    "L = the parabola this function represents\n",
    "\n",
    "delta r = displacment vector\n",
    "\n",
    "inverted delta f = gradient\n",
    "\n",
    "gradient is a slope, specifically the slope of the changing slope? aka acceleration? aka slope of non-linear functions?\n",
    "\n",
    "gradient descent: find a random point. then check around it in steps to find the largest slope, aka gradient, and go in opposite direction to continuely find the slope \"largest slope\" smaller and smaller until it settles in the minimum point in the parabaloid/nth dimensional shape.\n",
    "\n",
    "w0 is bias\n",
    "\n",
    "w1 is a feature/ vector of slope of features?\n",
    "\n",
    "beta0 is gradient?\n",
    "\n",
    "RSS is residual sum of squares: level of variance in a regression model in units of residuals/error term. The sum of the squared value of x, y, m, and b. the sum of errors squared\n",
    "\n",
    "RMSE is root mean squared error: the average error between a data point and the regression line\n",
    "\n",
    "m = slope\n",
    "\n",
    "b = y-int\n",
    "\n",
    "b = bias\n",
    "\n",
    "Residual is how far off a datapoint is from out regression line. in units of relavant variable (ex: $, lbs, mph, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x, y\n",
    "\n",
    "x, y, i, N, w1 = symbols(\"x, y, i, N, w1\")\n",
    "L = summation((Indexed('y',i) - Indexed('x',i)*w1)**2 ,(i,1,N))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = diff(L, w1) #derivative of L with respect to w1\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99 percent of problems will be solved with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(X): #ask about this later. Does this create a normal distribution/weight for all features/values in said features?\n",
    "    num_features = X.shape[1]\n",
    "    w_0 = np.random.normal(loc =0 , \n",
    "                           scale = 4, \n",
    "                           size = (num_features,\n",
    "                                   1))\n",
    "    \n",
    "    return w_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't model the target labels $y$ vs features $X$ directly\n",
    "- Model the probability $P(sex = 1| mass)$ \n",
    "- we only need to focus on one sex because it is binary, and the other probabilty is one minus this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision criterion of classifier based on probability\n",
    "\n",
    "- When $P(sex = 1| mass) > 0.5 \\rightarrow$ Class 1\n",
    "- When $P(sex = 1| mass) \\leq 0.5 \\rightarrow$ Class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single feature $X$, the sigmoid function takes a form:\n",
    "\n",
    "$$ \\sigma(x | w_1, w_0) = \\frac{1}{1 + exp\\Big[-(w x + b)\\Big]} $$\n",
    "\n",
    "where $w$ is a weight parameter and $b$ is a bias parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/weight is vector, and the perpindicular line is the descision boundry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
