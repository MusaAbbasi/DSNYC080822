{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a class\n",
    "class ExampleClass:\n",
    "    pass #at a minimum an empty class must contain pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    \n",
    "    def bark(self):\n",
    "        return 'I am actually going to bark this time. bark!'\n",
    "        \n",
    "    def who_am_i(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to use a class and the defined instance methods\n",
    "rex = Dog()\n",
    "print(rex.bark())\n",
    "print(rex.who_am_i())\n",
    "rex == rex.who_am_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes = Fields, properties of object insatance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of super and subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Musician(object):\n",
    "    \n",
    "    def __init__(self, name): # We'll set name at instantiation time to demonstrate passing in arguments to super().__init__()\n",
    "        self.name = name\n",
    "        self.band = \"The Beatles\"\n",
    "    \n",
    "    def tune_instrument(self):\n",
    "        print(\"Tuning Instrument!\")\n",
    "    \n",
    "    def practice(self):\n",
    "        print(\"Practicing!\")\n",
    "        \n",
    "    def perform(self):\n",
    "        print(\"Hello New York!\")\n",
    "        \n",
    "class Singer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)  # Notice how we pass in name argument from init to the super().__init() method, because it expects it\n",
    "        self.role = \"Singer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print(\"No tuning needed -- I'm a singer!\")\n",
    "    \n",
    "class Guitarist(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"Strumming the old 6 string!\")\n",
    "        \n",
    "class Bass_Guitarist(Guitarist):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Bass Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"I play the Seinfeld Theme Song when I get bored\")\n",
    "        \n",
    "    def perform(self):\n",
    "        super().perform()\n",
    "        print(\"Thanks for coming out!\")\n",
    "        \n",
    "class Drummer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Drummer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print('Where did I put those drum sticks?')\n",
    "        \n",
    "    def practice(self):\n",
    "        print('Why does my chair still say \"Pete Best\"?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative: $$ \\frac{df(x)}{dx} $$\n",
    "\n",
    "The instaneous slope of $f(x)$ at $x = c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define as limit of slope of chord between f(x + h) and f(x): $$\\frac{\\Delta y}{\\Delta x} $$ \n",
    "- As $\\Delta x \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding $w_1$ minimizing cost function:\n",
    "\n",
    "$$L = \\sum_{i=1}^N (y_i - x_i w_1)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "w = weight\n",
    "\n",
    "L = the parabola this function represents\n",
    "\n",
    "delta r = displacment vector\n",
    "\n",
    "inverted delta f = gradient\n",
    "\n",
    "gradient is a slope, specifically the slope of the changing slope? aka acceleration? aka slope of non-linear functions?\n",
    "\n",
    "gradient descent: find a random point. then check around it in steps to find the largest slope, aka gradient, and go in opposite direction to continuely find the slope \"largest slope\" smaller and smaller until it settles in the minimum point in the parabaloid/nth dimensional shape.\n",
    "\n",
    "w0 is bias\n",
    "\n",
    "w1 is a feature/ vector of slope of features?\n",
    "\n",
    "beta0 is gradient?\n",
    "\n",
    "RSS is residual sum of squares: level of variance in a regression model in units of residuals/error term. The sum of the squared value of x, y, m, and b. the sum of errors squared\n",
    "\n",
    "RMSE is root mean squared error: the average error between a data point and the regression line\n",
    "\n",
    "m = slope\n",
    "\n",
    "b = y-int\n",
    "\n",
    "b = bias\n",
    "\n",
    "Residual is how far off a datapoint is from out regression line. in units of relavant variable (ex: $, lbs, mph, etc...)\n",
    "\n",
    "$\\hat{y}$ = predicted value of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x, y\n",
    "\n",
    "x, y, i, N, w1 = symbols(\"x, y, i, N, w1\")\n",
    "L = summation((Indexed('y',i) - Indexed('x',i)*w1)**2 ,(i,1,N))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = diff(L, w1) #derivative of L with respect to w1\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99 percent of problems will be solved with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(X): #ask about this later. Does this create a normal distribution/weight for all features/values in said features?\n",
    "    num_features = X.shape[1]\n",
    "    w_0 = np.random.normal(loc =0 , \n",
    "                           scale = 4, \n",
    "                           size = (num_features,\n",
    "                                   1))\n",
    "    \n",
    "    return w_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't model the target labels $y$ vs features $X$ directly\n",
    "- Model the probability $P(sex = 1| mass)$ \n",
    "- we only need to focus on one sex because it is binary, and the other probabilty is one minus this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into X and y\n",
    "y = df[\"target\"]\n",
    "X = df.drop(columns = [\"target\"], axis = 1)\n",
    "\n",
    "# Split the data into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate LogisticRegression\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "\n",
    "# Fit to training data\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision criterion of classifier based on probability\n",
    "\n",
    "- When $P(sex = 1| mass) > 0.5 \\rightarrow$ Class 1\n",
    "- When $P(sex = 1| mass) \\leq 0.5 \\rightarrow$ Class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single feature $X$, the sigmoid function takes a form:\n",
    "\n",
    "$$ \\sigma(x | w_1, w_0) = \\frac{1}{1 + exp\\Big[-(w x + b)\\Big]} $$\n",
    "\n",
    "where $w$ is a weight parameter and $b$ is a bias parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/weight is vector, and the perpindicular line is the descision boundry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_True Positives (TP)_**: The number of observations where the model predicted the person has the disease (1), and they actually do have the disease (1).\n",
    "\n",
    "**_True Negatives (TN)_**: The number of observations where the model predicted the person is healthy (0), and they are actually healthy (0).\n",
    "\n",
    "**_False Positives (FP)_**: The number of observations where the model predicted the person has the disease (1), but they are actually healthy (0). \n",
    "\n",
    "**_False Negatives (FN)_**: The number of observations where the model predicted the person is healthy (0), but they actually have the disease (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "example_labels = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]\n",
    "example_preds  = [0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "cf = confusion_matrix(example_labels, example_preds)\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions/labels are either 0 or 1. The confusion matrix shows:\n",
    "\n",
    "- 2 values of 0 were correctly predicted as 0\n",
    "- 3 values of 0 were falsely predicted as 1\n",
    "- 2 values of 1 were falselt predicted as 0\n",
    "- 4 values of 1 were correctly predicted as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize your confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "pcf = plot_confusion_matrix(estimator= logreg, y_true = y_test, X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision measures how precise the predictions are\n",
    "- Recall indicates what percentage of the classes we're interested in were actually captured by the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{Precision} = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}} $    \n",
    "\n",
    "$ \\text{Recall} = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}} $\n",
    "\n",
    "aka true positives / true positives plus false negatives\n",
    "  \n",
    "$ \\text{Accuracy} = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}} $\n",
    "\n",
    "$ \\text{F1 score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $\n",
    "F1 score represents the Harmonic Mean of Precision and Recall\n",
    "this means that the F1 score cannot be high without both precision and recall also being high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the classification_report() function in the sklearn.metrics module, which takes labels and predictions and returns the precision, recall, F1 score and support (number of occurrences of each label in y_true) for the results of a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(precision_score(y_test,y_hat_test))\n",
    "print(precision_score(y_train,y_hat_train))\n",
    "\n",
    "print(recall_score(y_test,y_hat_test))\n",
    "print(recall_score(y_train,y_hat_train))\n",
    "\n",
    "print(accuracy_score(y_test,y_hat_test))\n",
    "print(accuracy_score(y_train,y_hat_train))\n",
    "\n",
    "print(f1_score(y_test,y_hat_test))\n",
    "print(f1_score(y_train,y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
    "...         X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC (reciever operator characteristic) is named for/was identified during world war 2 to identify japanease planes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\alpha$ is the false positive rate (reject null when null is true)\n",
    "- $\\beta$ is false negative rate (accept null when null is false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha$ and $\\beta$ depends on:\n",
    "- significance level\n",
    "- the structure of the hypothesis test (distribution, type of test, etc.)\n",
    "- the data (sample size, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True positive rate: $$ \\frac{TP}{TP+FN}$$\n",
    "\n",
    "Rate of correctly rejecting null (statistical power)\n",
    "\n",
    "- False positive rate: $$ \\frac{FP}{FP+TN}$$\n",
    "\n",
    "Rate of falsely rejecting null (Type I error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose optimal threshold that maximizes:\n",
    "    \n",
    "$$ J = TPR - FPR $$\n",
    "\n",
    "Want as many true positive identifcations while minimizing false positives \n",
    "\n",
    "**Known as Youden's J-statistic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recomennded to do a confusion matrix and classification report on the new y_pred_thresh against our initial y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_data = pd.read_csv('Phase3_Topic26_Classification_Metrics/Data/heart.csv')\n",
    "hd_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "hd_X = hd_data.drop('target', axis=1)\n",
    "hd_y = hd_data['target']\n",
    "\n",
    "hd_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_y.value_counts() # 1 = heart disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(hd_X, hd_y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "hd_scaler = StandardScaler()\n",
    "hd_scaler.fit(X_train)\n",
    "X_train_sc = hd_scaler.transform(X_train)\n",
    "X_test_sc = hd_scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "hd_model = LogisticRegression()\n",
    "hd_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = hd_model.predict(X_test_sc)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = hd_model.predict_proba(X_test_sc)\n",
    "y_prob[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_df = pd.DataFrame({'threshold': thresholds,\n",
    "                          'tpr':  tpr, 'fpr': fpr}).iloc[1::, :]\n",
    "thresh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(hd_model, X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_df['J_stat'] = \\\n",
    "thresh_df['tpr'] - thresh_df['fpr']\n",
    "thresh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_df.plot(x = 'threshold', y= 'J_stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_selector = \\\n",
    "thresh_df.index == thresh_df['J_stat'].idxmax()\n",
    "\n",
    "optimal_thresh = thresh_df[max_selector]\n",
    "optimal_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax, label = 'ROC')\n",
    "optimal_thresh.plot.scatter(x = 'fpr', y = 'tpr', c ='r', s = 100, ax = ax, label = 'optimal' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = optimal_thresh['threshold'].values\n",
    "# yes...this is the way to do it for binary class.\n",
    "y_pred_with_threshold = (y_prob[:,1] >= thresh).astype(int)\n",
    "y_pred_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the probabilitiy predictions for the \"1\" class (heart disease)\n",
    "y_hat_hd = y_prob[:, 1]\n",
    "\n",
    "roc_auc_score(y_test, y_hat_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "C_list = [1e-3, 1e-2, 1e-1, 1, 10, 100, 1e3, 1e4]\n",
    "k_list = np.arange(k)\n",
    "cv_scores = []\n",
    "\n",
    "for c in C_list :\n",
    "    logreg = LogisticRegression(C = c)\n",
    "    cv_loop_results = cross_validate(\n",
    "                X=X_train_sc, \n",
    "                y=y_train,\n",
    "                estimator=logreg, \n",
    "                cv=k,\n",
    "                scoring=('roc_auc')) #the scoring is the roc auc\n",
    "    cv_scores.append(dict(zip(k_list,cv_loop_results['test_score'])))\n",
    "    \n",
    "cv_score_df = pd.DataFrame(cv_scores) \n",
    "cv_score_df['C'] = C_list\n",
    "cv_score_df.set_index('C', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean roc auc score\n",
    "cv_score_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select $C = 0.1$ as best regularization:\n",
    "- based on ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best = LogisticRegression(C = 0.1)\n",
    "logreg_best.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = logreg_best.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg_best.predict(X_test_sc)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_best, tpr_best, thresholds_best = roc_curve(y_test, y_pred_probs[:,1])\n",
    "bestmod_thresh_df = pd.DataFrame({'threshold': thresholds_best,\n",
    "                          'tpr':  tpr_best, 'fpr': fpr_best, 'J_stat': tpr_best - fpr_best}).iloc[1::, :]\n",
    "bestmod_thresh_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = bestmod_thresh_df['J_stat'].idxmax()\n",
    "best_point = pd.DataFrame(bestmod_thresh_df.iloc[best_idx]).T\n",
    "best_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'tpr', ax = ax[0])\n",
    "bestmod_thresh_df.plot(x = 'threshold', y = 'fpr', ax = ax[0])\n",
    "ax[0].axvline(best_point['threshold'].values, c = 'r', linestyle = '--')\n",
    "\n",
    "bestmod_thresh_df.plot(x = 'fpr', y = 'tpr', ax = ax[1], label = 'ROC')\n",
    "best_point.plot.scatter(x = 'fpr', y = 'tpr', ax = ax[1], c ='r', s = 100, label = 'Optimal')\n",
    "ax[1].set_ylabel('True positive rate')\n",
    "ax[1].set_xlabel('False positive rate')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter on class 1 probabilities\n",
    "y_pred_best_with_threshold = (y_pred_probs[:,1] >= 0.4).astype(int)\n",
    "y_pred_best_with_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_best_with_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_best = confusion_matrix(y_test, y_pred_best_with_threshold)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(conf_mat_best, annot = True, ax = ax)\n",
    "ax.set_ylabel(r'$y_{true}$', size = 15)\n",
    "ax.set_xlabel(r'$y_{pred}$', size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_best_with_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest neighbors and dimentionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $k$: number of neighbors\n",
    " \n",
    " low $k$ = low bias, high varience model\n",
    " \n",
    " high $k$ = high bias, low varience : too rigid/not sensative enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('Phase3_Topic28_KNearest_Neighbors_Curse_of_Dimensionality//Data/Iris.csv').drop(columns = ['Id'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_transform = LabelEncoder()\n",
    "iris_df['Species'] = target_transform.fit_transform(iris_df['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(hue = 'Species', data = iris_df, height = 1.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y = 'SepalWidthCm', x = 'PetalWidthCm', hue = 'Species', data = iris_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so whats next?\n",
    "X = iris_df[['SepalWidthCm', 'PetalWidthCm']]\n",
    "y = iris_df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split, stratify keeps target distribution same in train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split(X, y, stratify = y, test_size = 0.15, random_state = 42) stratify keeps the percentages the same in both the test and train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X / features do not need to be scaled in descision trees\n",
    "- Can improve with more features\n",
    "- Entropy is a measure of how evenly mixed a class is. 0 is the lowest, 1 is the highest\n",
    "- Where probability of all classes is equal, entropy is 1.\n",
    "- Where entropy is .5 of two items in a class, entropy is 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipe?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv('Phase3_Topic30_ModelTuning/Data/Iris.csv').drop(columns = ['Id'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_transform = LabelEncoder()\n",
    "iris_df['Species'] = target_transform.fit_transform(iris_df['Species'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['SepalWidthCm', 'SepalLengthCm']\n",
    "X = iris_df[col_list]\n",
    "y = iris_df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# this will allow us to visualize the pipeline (may not be available in learn-env)\n",
    "from sklearn import set_config\n",
    "set_config(display= 'diagram')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('imputer', SimpleImputer(strategy=\"median\")), ('std_scaler', StandardScaler()),\n",
    "        ('rf_clf', DecisionTreeClassifier(random_state=42))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "\n",
    "# Train the pipeline (tranformations & predictor)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the pipeline (includes the transfomers & trained predictor)\n",
    "predicted = pipeline.predict(X_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can define outside the cross validation\n",
    "steps = [('imputer', SimpleImputer(strategy=\"median\")), ('std_scaler', StandardScaler()),\n",
    "        ('rf_clf', DecisionTreeClassifier(random_state=42))]\n",
    "\n",
    "model_pipe = Pipeline(steps)\n",
    "model_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_validation_pip(X_train, y_train, estimator, num_split = 10):\n",
    "    \n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "    \n",
    "    score_train_list = []\n",
    "    score_val_list = []\n",
    "    \n",
    "    for train_index, valid_index in KFold(n_splits = num_split).split(X_train):\n",
    "        \n",
    "        # train and validation splitting \n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[valid_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[valid_index]\n",
    "\n",
    "        estimator.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # now how did we do?\n",
    "        accuracy_train = estimator.score(X_train_fold, y_train_fold)\n",
    "        accuracy_val = estimator.score(X_val_fold, y_val_fold)\n",
    "        score_val_list.append(accuracy_val)\n",
    "        score_train_list.append(accuracy_train)\n",
    "    \n",
    "    return {'train': np.mean(score_train_list), 'validation': np.mean(score_val_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_pip(X_train, y_train, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop the decision tree\n",
    "model_pipe.steps.pop(-1)\n",
    "# insert knn\n",
    "model_pipe.steps.append(\n",
    "['knn', KNeighborsClassifier()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final pipe?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.read_csv('Phase3_Topic30_ModelTuning/Data/Iris.csv').drop(columns = ['Id'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            5.1           3.5            1.4           0.2        0\n",
       "1            4.9           3.0            1.4           0.2        0\n",
       "2            4.7           3.2            1.3           0.2        0\n",
       "3            4.6           3.1            1.5           0.2        0\n",
       "4            5.0           3.6            1.4           0.2        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "target_transform = LabelEncoder()\n",
    "iris_df['Species'] = target_transform.fit_transform(iris_df['Species'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = ['SepalWidthCm', 'SepalLengthCm']\n",
    "X = iris_df[col_list]\n",
    "y = iris_df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a new pipeline object \n",
    "steps = [('imputer', SimpleImputer(strategy=\"median\")), ('std_scaler', StandardScaler()),\n",
    "        ('knn', KNeighborsClassifier())]\n",
    "\n",
    "model_pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_grid = {'imputer__strategy': [\"mean\", \"median\"],\n",
    "             'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15, 18],\n",
    "             'knn__p': [1, 2, 3, 4]}\n",
    "\n",
    "# note: default scoring is aaccuracy\n",
    "gs_pipe = GridSearchCV(estimator=model_pipe, \n",
    "                       param_grid=pipe_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying different metrics:\n",
    "- Default scoring was accuracy\n",
    "- But can try other with scoring = '\n",
    "- Takes string:\n",
    "    - 'average_precision'\n",
    "    - 'balanced_accuracy' (class averaged recall)\n",
    "    - 'roc_auc', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imputer__strategy': 'mean', 'knn__n_neighbors': 18, 'knn__p': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811076923076923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer()), ('std_scaler', StandardScaler()),\n",
       "                ('knn', KNeighborsClassifier(n_neighbors=18, p=1))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = gs_pipe.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x169da9dcb80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.62      0.62      0.62         8\n",
      "           2       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.75      0.75      0.75        23\n",
      "weighted avg       0.74      0.74      0.74        23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_imputer__strategy</th>\n",
       "      <th>param_knn__n_neighbors</th>\n",
       "      <th>param_knn__p</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>median</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>{'imputer__strategy': 'median', 'knn__n_neighb...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.811077</td>\n",
       "      <td>0.045746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.009765</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>mean</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>{'imputer__strategy': 'mean', 'knn__n_neighbor...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.811077</td>\n",
       "      <td>0.045746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.006804</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>median</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>{'imputer__strategy': 'median', 'knn__n_neighb...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.803385</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>mean</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>{'imputer__strategy': 'mean', 'knn__n_neighbor...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.803385</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>median</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>{'imputer__strategy': 'median', 'knn__n_neighb...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.795692</td>\n",
       "      <td>0.026080</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "60       0.005135      0.000229         0.003591        0.000802   \n",
       "28       0.009765      0.000720         0.007288        0.000416   \n",
       "61       0.006804      0.001159         0.004813        0.002271   \n",
       "29       0.009893      0.000537         0.007153        0.000316   \n",
       "62       0.006777      0.000484         0.004696        0.000768   \n",
       "\n",
       "   param_imputer__strategy param_knn__n_neighbors param_knn__p  \\\n",
       "60                  median                     18            1   \n",
       "28                    mean                     18            1   \n",
       "61                  median                     18            2   \n",
       "29                    mean                     18            2   \n",
       "62                  median                     18            3   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "60  {'imputer__strategy': 'median', 'knn__n_neighb...           0.769231   \n",
       "28  {'imputer__strategy': 'mean', 'knn__n_neighbor...           0.769231   \n",
       "61  {'imputer__strategy': 'median', 'knn__n_neighb...           0.769231   \n",
       "29  {'imputer__strategy': 'mean', 'knn__n_neighbor...           0.769231   \n",
       "62  {'imputer__strategy': 'median', 'knn__n_neighb...           0.769231   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "60           0.846154                0.8               0.76   \n",
       "28           0.846154                0.8               0.76   \n",
       "61           0.807692                0.8               0.80   \n",
       "29           0.807692                0.8               0.80   \n",
       "62           0.769231                0.8               0.80   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "60               0.88         0.811077        0.045746                1  \n",
       "28               0.88         0.811077        0.045746                1  \n",
       "61               0.84         0.803385        0.022577                3  \n",
       "29               0.84         0.803385        0.022577                3  \n",
       "62               0.84         0.795692        0.026080                5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_df = pd.DataFrame(gs_pipe.cv_results_)\n",
    "cv_result_df = cv_result_df.sort_values(by = 'rank_test_score')\n",
    "cv_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian hyperparameter optimization hpyeropt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
