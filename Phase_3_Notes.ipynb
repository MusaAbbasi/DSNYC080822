{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOP Object Oriented Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a class\n",
    "class ExampleClass:\n",
    "    pass #at a minimum an empty class must contain pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dog:\n",
    "    \n",
    "    def bark(self):\n",
    "        return 'I am actually going to bark this time. bark!'\n",
    "        \n",
    "    def who_am_i(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am actually going to bark this time. bark!\n",
      "<__main__.Dog object at 0x000002A2A7736280>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to use a class and the defined instance methods\n",
    "rex = Dog()\n",
    "print(rex.bark())\n",
    "print(rex.who_am_i())\n",
    "rex == rex.who_am_i()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes = Fields, properties of object insatance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of super and subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Musician(object):\n",
    "    \n",
    "    def __init__(self, name): # We'll set name at instantiation time to demonstrate passing in arguments to super().__init__()\n",
    "        self.name = name\n",
    "        self.band = \"The Beatles\"\n",
    "    \n",
    "    def tune_instrument(self):\n",
    "        print(\"Tuning Instrument!\")\n",
    "    \n",
    "    def practice(self):\n",
    "        print(\"Practicing!\")\n",
    "        \n",
    "    def perform(self):\n",
    "        print(\"Hello New York!\")\n",
    "        \n",
    "class Singer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)  # Notice how we pass in name argument from init to the super().__init() method, because it expects it\n",
    "        self.role = \"Singer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print(\"No tuning needed -- I'm a singer!\")\n",
    "    \n",
    "class Guitarist(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"Strumming the old 6 string!\")\n",
    "        \n",
    "class Bass_Guitarist(Guitarist):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Bass Guitarist\"\n",
    "        \n",
    "    def practice(self):\n",
    "        print(\"I play the Seinfeld Theme Song when I get bored\")\n",
    "        \n",
    "    def perform(self):\n",
    "        super().perform()\n",
    "        print(\"Thanks for coming out!\")\n",
    "        \n",
    "class Drummer(Musician):\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "        self.role = \"Drummer\"\n",
    "        \n",
    "    def tune_instrument(self):\n",
    "        print('Where did I put those drum sticks?')\n",
    "        \n",
    "    def practice(self):\n",
    "        print('Why does my chair still say \"Pete Best\"?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative: $$ \\frac{df(x)}{dx} $$\n",
    "\n",
    "The instaneous slope of $f(x)$ at $x = c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define as limit of slope of chord between f(x + h) and f(x): $$\\frac{\\Delta y}{\\Delta x} $$ \n",
    "- As $\\Delta x \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding $w_1$ minimizing cost function:\n",
    "\n",
    "$$L = \\sum_{i=1}^N (y_i - x_i w_1)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "w = weight\n",
    "\n",
    "L = the parabola this function represents\n",
    "\n",
    "delta r = displacment vector\n",
    "\n",
    "inverted delta f = gradient\n",
    "\n",
    "gradient is a slope, specifically the slope of the changing slope? aka acceleration? aka slope of non-linear functions?\n",
    "\n",
    "gradient descent: find a random point. then check around it in steps to find the largest slope, aka gradient, and go in opposite direction to continuely find the slope \"largest slope\" smaller and smaller until it settles in the minimum point in the parabaloid/nth dimensional shape.\n",
    "\n",
    "w0 is bias\n",
    "\n",
    "w1 is a feature/ vector of slope of features?\n",
    "\n",
    "beta0 is gradient?\n",
    "\n",
    "RSS is residual sum of squares: level of variance in a regression model in units of residuals/error term. The sum of the squared value of x, y, m, and b. the sum of errors squared\n",
    "\n",
    "RMSE is root mean squared error: the average error between a data point and the regression line\n",
    "\n",
    "m = slope\n",
    "\n",
    "b = y-int\n",
    "\n",
    "b = bias\n",
    "\n",
    "Residual is how far off a datapoint is from out regression line. in units of relavant variable (ex: $, lbs, mph, etc...)\n",
    "\n",
    "$\\hat{y}$ = predicted value of y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy.abc import x, y\n",
    "\n",
    "x, y, i, N, w1 = symbols(\"x, y, i, N, w1\")\n",
    "L = summation((Indexed('y',i) - Indexed('x',i)*w1)**2 ,(i,1,N))\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = diff(L, w1) #derivative of L with respect to w1\n",
    "grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99 percent of problems will be solved with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(X): #ask about this later. Does this create a normal distribution/weight for all features/values in said features?\n",
    "    num_features = X.shape[1]\n",
    "    w_0 = np.random.normal(loc =0 , \n",
    "                           scale = 4, \n",
    "                           size = (num_features,\n",
    "                                   1))\n",
    "    \n",
    "    return w_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Don't model the target labels $y$ vs features $X$ directly\n",
    "- Model the probability $P(sex = 1| mass)$ \n",
    "- we only need to focus on one sex because it is binary, and the other probabilty is one minus this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-935cec13e084>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Split data into X and y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into X and y\n",
    "y = df[\"target\"]\n",
    "X = df.drop(columns = [\"target\"], axis = 1)\n",
    "\n",
    "# Split the data into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size = .25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-56e40ecf2aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Fit to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel_log\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate LogisticRegression\n",
    "logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='liblinear')\n",
    "\n",
    "# Fit to training data\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision criterion of classifier based on probability\n",
    "\n",
    "- When $P(sex = 1| mass) > 0.5 \\rightarrow$ Class 1\n",
    "- When $P(sex = 1| mass) \\leq 0.5 \\rightarrow$ Class 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single feature $X$, the sigmoid function takes a form:\n",
    "\n",
    "$$ \\sigma(x | w_1, w_0) = \\frac{1}{1 + exp\\Big[-(w x + b)\\Big]} $$\n",
    "\n",
    "where $w$ is a weight parameter and $b$ is a bias parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/weight is vector, and the perpindicular line is the descision boundry "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_True Positives (TP)_**: The number of observations where the model predicted the person has the disease (1), and they actually do have the disease (1).\n",
    "\n",
    "**_True Negatives (TN)_**: The number of observations where the model predicted the person is healthy (0), and they are actually healthy (0).\n",
    "\n",
    "**_False Positives (FP)_**: The number of observations where the model predicted the person has the disease (1), but they are actually healthy (0). \n",
    "\n",
    "**_False Negatives (FN)_**: The number of observations where the model predicted the person is healthy (0), but they actually have the disease (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [2, 4]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "example_labels = [0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1]\n",
    "example_preds  = [0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1]\n",
    "\n",
    "cf = confusion_matrix(example_labels, example_preds)\n",
    "cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions/labels are either 0 or 1. The confusion matrix shows:\n",
    "\n",
    "- 2 values of 0 were correctly predicted as 0\n",
    "- 3 values of 0 were falsely predicted as 1\n",
    "- 2 values of 1 were falselt predicted as 0\n",
    "- 4 values of 1 were correctly predicted as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f40f1e66f40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize your confusion matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpcf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'logreg' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize your confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "pcf = plot_confusion_matrix(estimator= logreg, y_true = y_test, X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision measures how precise the predictions are\n",
    "- Recall indicates what percentage of the classes we're interested in were actually captured by the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\text{Precision} = \\frac{\\text{Number of True Positives}}{\\text{Number of Predicted Positives}} $    \n",
    "\n",
    "$ \\text{Recall} = \\frac{\\text{Number of True Positives}}{\\text{Number of Actual Total Positives}} $\n",
    "\n",
    "aka true positives / all values identified as positive\n",
    "  \n",
    "$ \\text{Accuracy} = \\frac{\\text{Number of True Positives + True Negatives}}{\\text{Total Observations}} $\n",
    "\n",
    "$ \\text{F1 score} = 2 * \\frac{\\text{Precision * Recall}}{\\text{Precision + Recall}} $\n",
    "F1 score represents the Harmonic Mean of Precision and Recall\n",
    "this means that the F1 score cannot be high without both precision and recall also being high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the classification_report() function in the sklearn.metrics module, which takes labels and predictions and returns the precision, recall, F1 score and support (number of occurrences of each label in y_true) for the results of a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(precision_score(y_test,y_hat_test))\n",
    "print(precision_score(y_train,y_hat_train))\n",
    "\n",
    "print(recall_score(y_test,y_hat_test))\n",
    "print(recall_score(y_train,y_hat_train))\n",
    "\n",
    "print(accuracy_score(y_test,y_hat_test))\n",
    "print(accuracy_score(y_train,y_hat_train))\n",
    "\n",
    "print(f1_score(y_test,y_hat_test))\n",
    "print(f1_score(y_train,y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7873ccdfd001>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[1;32m----> 3\u001b[1;33m         X, y, random_state=0)\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
    "...         X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
